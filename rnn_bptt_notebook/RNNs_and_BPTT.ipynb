{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training RNNs by BPTT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will take you through the process of constructing a Backpropagation Through Time (BPTT) graph and using it to optimize a simple recurrent neural network (RNN). In particular, we'll use it to train a network to predict the next frame of some videos from a simple synthetic video dataset. After training the network we'll sample it's predictions to demonstrate that it has learned a precise model of input videos.\n",
    "\n",
    "There several dependencies that you will need to have installed for this notebook to work. Most notably:\n",
    "- tensorflow\n",
    "- pyyaml\n",
    "- ffmpeg (or another suitable video backend for matplotlib)\n",
    "\n",
    "The tensorflow and pyyaml can be obtained from pip. ffmpeg can be downloaded from https://www.ffmpeg.org/download.html. You will need to make sure ffmpeg binary is placed in a folder that is accessed by your $PATH environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import yaml\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys, os\n",
    "import pprint\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.image as image\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hippo.util as util\n",
    "from hippo.util import Peace\n",
    "from hippo.networks import Network\n",
    "import hippo.data as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to fix a random seed to ensure reproducible behavior-- feel free to try a different seed-- you may get slightly different behavior particularly in how quickly the training error converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll load a bunch parameters: parameters for generating the data set, parameters to specify the network itself, parameters used to optimize the network during training. These all get stored in a hparams hash. We'll pass this around through much of the rest of the code.\n",
    "\n",
    "If you're curious about what one of them does after you've finished a first pass through the notebook, you're welcome to try changing its value and rerunning the rest of the notebook. I can't promise it won't break the rest of the code though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hparams = util.load_params('bouncing_block_prediction.yaml')\n",
    "\n",
    "print('-------------')\n",
    "print('Running on the following params:')\n",
    "pprint.pprint(hparams)\n",
    "print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll generate a synthetic dataset-- videos of a small block bouncing with random velocity within the image frame. Of course it's always important to separate training data from validation and test data so we do that right from beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data.gen_datasets(hparams)\n",
    "\n",
    "# Our parameter files leave the network input and output dimension unspecified since they often\n",
    "# will depend on the data\n",
    "hparams['layers'][0]['dim'] = hparams['data']['dim']\n",
    "hparams['layers'][-1]['dim'] = hparams['data']['dim']\n",
    "\n",
    "print ('The completed network structure parameters:')\n",
    "pprint.pprint(hparams['layers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out what one the videos in our dataset looks like. Change the index into the training data below if you want to see a different video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = train_data[0]\n",
    "\n",
    "fig = plt.figure()\n",
    "axis_image = plt.imshow(video[0,:,:], cmap=\"Greys_r\", interpolation=\"none\", animated=True)\n",
    "\n",
    "def init():\n",
    "    axis_image.set_clim(vmin=0.0, vmax=1.0)\n",
    "    return axis_image,\n",
    "\n",
    "def update(i):\n",
    "    axis_image.set_array(video[i,:,:])\n",
    "    return axis_image,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, init_func=init, frames=range(video.shape[0]), interval=50, blit=True)\n",
    "\n",
    "\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to set up a network. The Network class takes the hyper parameters and allocates weights for each of the specified layers. It also provides the step function we'll use when building a BPTT training graph and functions for saving and reseting network state that are used to allow the network state to carry across truncation boundaries in during truncated BPTT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network(hparams):\n",
    "    with tf.name_scope('network_parameters'):\n",
    "        net = Network(hparams)\n",
    "\n",
    "    return net\n",
    "\n",
    "net = build_network(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the function unfolds the recurrent computation in time, i.e. let's build the BPTT graph. This basically just requires iterating the step function of the network we've created, but we'll also need to create input variables, and compute a loss (the code currently uses the L2 distance).\n",
    "\n",
    "The network's step function takes an input and produces a new hidden state of it's RNN layer from the old hidden state and the input. Then it computes a linear function of the hidden state to produce an output at each timestep. The actual math of this is hidden away in hippo/networks.py nad hippo/layers.py. Feel to check them out if you are interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_forward_prop_graph(net, n_batch, n_prop, n_reject, summarize, hparams):\n",
    "    # The network input and teacher signal nodes\n",
    "    # They reference the same placeholders because we are doing input prediction\n",
    "    # TODO: update this to the more general context\n",
    "    # The forward propagation graph\n",
    "    xs, ys, ys_valid, ys_hat, losses = [], [], [], [], []\n",
    "\n",
    "\n",
    "    with tf.name_scope('t_0'):\n",
    "        train_state_store = net.get_new_state_store(n_batch)\n",
    "        train_state = net.state_from_store(train_state_store)\n",
    "\n",
    "    last_state = []\n",
    "\n",
    "    for i in range(n_prop):\n",
    "        with tf.name_scope('t_' + str(i+1)):\n",
    "            x_batch = tf.placeholder(tf.float32, shape=[n_batch, *net.input_dim], name = 'x')\n",
    "            y_batch = tf.placeholder(tf.float32, shape=[n_batch, *net.input_dim], name = 'y')\n",
    "            y_valid_batch = tf.placeholder(tf.bool, shape=[n_batch], name = 'y_valid')\n",
    "\n",
    "            xs.append(x_batch)\n",
    "            ys.append(y_batch)\n",
    "            ys_valid.append(y_valid_batch)\n",
    "\n",
    "\n",
    "            train_state, [y_hat_batch] = net.step(train_state, x_batch)\n",
    "            ys_hat.append(y_hat_batch)\n",
    "\n",
    "            if i == n_prop - n_reject - 1:\n",
    "                last_state = train_state\n",
    "\n",
    "            # We want to ignore first n_bptt_reject outputs on this since\n",
    "            # their gradient calculations will significantly more biased the\n",
    "            # later outputs\n",
    "            if i >= n_reject:\n",
    "                loss = data.loss(hparams, y_hat_batch, y_batch, y_valid_batch)\n",
    "                losses.append(loss)\n",
    "\n",
    "    # This update that allows state to carry across f-props so our network\n",
    "    # state can carry info across arbitrarily long input histories\n",
    "    with tf.name_scope('save_and_reset'):\n",
    "        store_state_op = net.store_state_op(last_state, train_state_store)\n",
    "        reset_state_op = net.reset_state_op(train_state_store)\n",
    "\n",
    "\n",
    "    # Our training objective function\n",
    "    with tf.name_scope('loss_statistics'):\n",
    "        all_losses = tf.stack(losses, name='all_losses')\n",
    "        mean_loss = tf.reduce_mean(all_losses, name='mean_loss')\n",
    "\n",
    "    Graph_Components = namedtuple('BPTT_Graph',\n",
    "        'xs ys ys_valid ys_hat err_func state_store_op reset_state_op')\n",
    "    graph_components = Graph_Components(xs=xs, ys = ys, ys_valid = ys_valid,\n",
    "        ys_hat = ys_hat, err_func=mean_loss, state_store_op=store_state_op,\n",
    "        reset_state_op=reset_state_op)\n",
    "\n",
    "    return graph_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this function to build our BPTT training graph. We'll also use it to build a single timestep version of the graph which is useful for things like sampling the network's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_train_graph(net, hparams):\n",
    "    n_batch = hparams['n_batch']\n",
    "    n_prop = hparams['n_prop']\n",
    "    n_reject = hparams['n_reject']\n",
    "\n",
    "    with tf.name_scope('BPTT_Graph'):\n",
    "        return build_forward_prop_graph(net, n_batch, n_prop, n_reject, True, hparams)\n",
    "\n",
    "def build_sampling_graph(net, hparams):\n",
    "    n_batch = 1\n",
    "    n_prop = 1\n",
    "    n_reject = 0\n",
    "\n",
    "    with tf.name_scope('Sampler_Graph'):\n",
    "        return build_forward_prop_graph(net, n_batch, n_prop, n_reject, False, hparams)\n",
    "    \n",
    "train_components = build_train_graph(net, hparams)\n",
    "sampler_components = build_sampling_graph(net, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last piece of our graph is optimizer. This is what we use to compute gradients of the loss function and update the weights accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(err_func, hparams):\n",
    "    opt_params = hparams['optimizer']\n",
    "\n",
    "    with tf.name_scope('optimizer'):\n",
    "        t = tf.Variable(0, name= 't', trainable=False) # the step variable\n",
    "\n",
    "        steps_til_decay = opt_params.get('steps_til_decay', 2000)\n",
    "        decay_factor = opt_params.get('eta_decay_factor', .5)\n",
    "        staircase = opt_params.get('staircase', True)\n",
    "        grad_clip_norm = opt_params.get('grad_clip_norm', 1.0)\n",
    "\n",
    "        if opt_params['algorithm'] == 'adam':\n",
    "            eta = tf.train.exponential_decay(opt_params['eta0'], t, steps_til_decay,\n",
    "                decay_factor, staircase=staircase)\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=eta)\n",
    "        elif opt_params['algorithm'] == 'sgd':\n",
    "            eta = tf.train.exponential_decay(opt_params['eta0'], t, steps_til_decay,\n",
    "                decay_factor, staircase=staircase)\n",
    "            optimizer = tf.train.GradientDescentOptimizer(eta)\n",
    "        else:\n",
    "            raise Exception('I dunno nothing about that optimizer')\n",
    "\n",
    "        grads, params = zip(*optimizer.compute_gradients(err_func))\n",
    "        clipped_grads, _ = tf.clip_by_global_norm(grads, grad_clip_norm)\n",
    "        optimize_op = optimizer.apply_gradients(zip(clipped_grads, params), global_step=t)\n",
    "\n",
    "\n",
    "    Optimizer = namedtuple('Optimizer', 'optimize_op t eta')\n",
    "    return Optimizer(optimize_op=optimize_op, t=t, eta=eta)\n",
    "\n",
    "optimizer = build_optimizer(train_components.err_func, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the graph is all together let's use tensorboard to take a look at it. The utility function used to do this in a notebook comes from the code snippet at: https://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "util.show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now that the graph is built we can use it to train our network. To do this we'll need to feed our BPTT graph with sequences of inputs and sequences of outputs. Since we are predicting the next frame of the video the outputs are just the inputs shifted forward by one timestep. First we create some classes to provide these sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_producer, output_producer = data.gen_prediction_data_producers(train_data, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to initialize network weights. To this we need to create as tensorflow session which will launch the graph on our compute hardware (CPU or GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "session.run(init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real work commences. We'll feed in the data and compute the forward propagation graph. In turn the optimizer, will run backpropagate the loss gradients and use them to update the network weights. First we'll just do 1000 iterations of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(session, train_components, optimizer, input_producer, \n",
    "    output_producer, n_train_steps, hparams):\n",
    "    '''\n",
    "    Run train the network in graph by optimizing it on the training inputs\n",
    "        @param graph: the tensorflow graph with bptt graph and optimizer\n",
    "        @param train_components: components of the bptt_graph (input, err, save, reset...)\n",
    "        @param optimizer: components of the optimizer graph (optimize_op, eta...)\n",
    "        @param input_producer: an object to supply input batches\n",
    "        @param output_producer: an object to supply output batches\n",
    "        @param save_state_op: op to save state across truncation boundaries\n",
    "        @param reset_state_op: op to reset state to some initialization\n",
    "        @param n_train_steps: the number of forward propagation to perform\n",
    "        @param hparams: bet you couldn't have guessed it's the hyperparameters\n",
    "\n",
    "        @return: the history the training error\n",
    "\n",
    "    TODO: start using a simulator and replace the input_generator with a world model ;)\n",
    "    '''\n",
    "\n",
    "    n_prop = hparams['n_prop']\n",
    "\n",
    "    train_error_hist = []\n",
    "    summary_error = 0.0\n",
    "    summary_freq = 100\n",
    "\n",
    "    start_step = optimizer.t.eval()\n",
    "    \n",
    "    for step in range(n_train_steps):\n",
    "\n",
    "        # assert 'train_state_reset_rate' in hparams\n",
    "        # reset_rate = n_prop/hparams['train_state_reset_rate']\n",
    "        # if np.random.poisson(reset_rate) > 0:\n",
    "        #     print('State reset!')\n",
    "        #     session.run([train_components.reset_state_op])\n",
    "\n",
    "        # Set up input value -> input var mapping\n",
    "        input_window, _  = input_producer.next_window()\n",
    "        output_window, is_valid = output_producer.next_window()\n",
    "        feed_dict = dict()\n",
    "        for i in range(n_prop):\n",
    "            feed_dict[train_components.xs[i]] = input_window[i]\n",
    "            feed_dict[train_components.ys[i]] = output_window[i]\n",
    "            feed_dict[train_components.ys_valid[i]] = is_valid[i]\n",
    "\n",
    "        to_compute = [train_components.err_func, optimizer.eta,\n",
    "            optimizer.optimize_op, train_components.state_store_op]\n",
    "        error_val, eta_val, _, _ = session.run(to_compute, feed_dict=feed_dict)\n",
    "\n",
    "        summary_error += error_val\n",
    "\n",
    "        if (step + 1) % summary_freq == 0 and step > 0:\n",
    "            mean_error = summary_error/summary_freq\n",
    "\n",
    "            train_error_hist.append((step + start_step + 1, mean_error))\n",
    "\n",
    "            print('Average error at step', step + start_step + 1, ':', mean_error, 'learning rate:', eta_val)\n",
    "            summary_error = 0.0\n",
    "\n",
    "\n",
    "    return util.nested_list_to_array(train_error_hist)\n",
    "\n",
    "train_error_hist = run_training(session, train_components, optimizer, input_producer, output_producer, 1000, hparams)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_error_hist[:,0], train_error_hist[:, 1])\n",
    "plt.title('training loss')\n",
    "plt.xlabel('training step')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained the model a bit let's sample from to see what it's predictions look like. When sampling from the model, we generally need to seed it with inputs to get its hidden state to point in the space that it is good at continuing from. In this case we'll use a few frames a video from the training data.\n",
    "\n",
    "After we've seed the hidden state we start to feed the network's own predictions into it as the next input. Using this approach the samples from the model will stay close to original input only if its predictions are very accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(session, sampler_components, seed, n_sample_steps, hparams):\n",
    "    n_seed = seed.shape[0]\n",
    "\n",
    "    input_producer = data.gen_one_step_producer(seed, hparams)\n",
    "    samples = []\n",
    "\n",
    "    y_hat = sampler_components.ys_hat[0]\n",
    "    if hparams['data']['type'] == 'video':\n",
    "        dist = y_hat # we currently just predict the mean so there's no good way of sampling\n",
    "    elif hparams['data']['type'] == 'text':\n",
    "        dist = tf.nn.softmax(y_hat)\n",
    "    else:\n",
    "        raise data.DataTypeException()\n",
    "\n",
    "    to_compute = [dist, sampler_components.state_store_op]\n",
    "\n",
    "    for step in range(n_seed):\n",
    "        input_window, _ = input_producer.next_window()\n",
    "\n",
    "        feed_dict = {sampler_components.xs[0]: input_window[0]}\n",
    "        dist, _ = session.run(to_compute, feed_dict = feed_dict)\n",
    "\n",
    "        prediction = data.sample_distribution(dist, hparams)\n",
    "\n",
    "\n",
    "    for step in range(n_sample_steps):\n",
    "        prediction = data.sample_distribution(dist, hparams)\n",
    "        samples.append(np.reshape(prediction, hparams['data']['frame_dim']))\n",
    "\n",
    "        if step == n_sample_steps - 1:\n",
    "            break # We already have sampled n_sample_steps times\n",
    "\n",
    "        feed_dict = {sampler_components.xs[0]: prediction}\n",
    "        dist, _ = session.run(to_compute, feed_dict = feed_dict)\n",
    "\n",
    "    return np.stack(samples)\n",
    "\n",
    "n_seed_frames = 10\n",
    "seed_idx = 0\n",
    "n_frames = hparams['data']['n_frames']\n",
    "n_samples = n_frames - n_seed_frames\n",
    "\n",
    "\n",
    "sample_seed = train_data[seed_idx][:n_seed_frames,:,:]\n",
    "samples = sample(session, sampler_components, sample_seed, n_samples, hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's compare the generated sample to the remainder of the video used to generate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_video = train_data[seed_idx][n_seed_frames:,:,:]\n",
    "\n",
    "h, w = hparams['data']['frame_dim']\n",
    "compare_video = np.zeros((n_samples, h, 2*w + 1))\n",
    "compare_video[:,:,:w] = orig_video\n",
    "compare_video[:,:,w] = .5\n",
    "compare_video[:,:,w+1:] = samples\n",
    "\n",
    "fig = plt.figure()\n",
    "axis_image = plt.imshow(compare_video[0,:,:], cmap=\"Greys_r\", interpolation=\"none\", animated=True)\n",
    "\n",
    "def init():\n",
    "    axis_image.set_clim(vmin=0.0, vmax=1.0)\n",
    "    return axis_image,\n",
    "\n",
    "def update(i):\n",
    "    axis_image.set_array(compare_video[i,:,:])\n",
    "    return axis_image,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, init_func=init, frames=range(compare_video.shape[0]), interval=50, blit=True)\n",
    "\n",
    "\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, it's not doing all that well yet. But don't despair we just need to do some more training. Try training for another 2000 steps and then sample from the net again.\n",
    "\n",
    "I'll leave this part to you. \n",
    "\n",
    "Note that the learning rate will automatically decrease by half after finish step 2000- this is because we set an annealing schedule for the learning rate when specified the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run the training for another 2000 steps and then sample from it again\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll probably see that the samples have improved significantly but they still start to degrade as the video goes on (it's also possible that samples will still be pretty shitty-- just keep training if that's the case). You're welcome to continue training if you like-- the samples will keep getting better as the training error goes down. \n",
    "\n",
    "Because all of the training has been done with clean frames from the synthetic video dataset, the network doesn't know what to do when encounters it's own sampling noise and can tend to amplify the noise as sampling continues. You might implement a strategy for training the network to be more robust to its own sampling noise.\n",
    "\n",
    "Alternatively, do you remember that train/validate/test split we made at the beginning of notebook? Every true devotee of the church of machine learning knows that it's most foul vanity to assume your model is doing well just because it has a good training error. We must be ever vigilant against the sin of overfitting. You better go back and see how your model does the test set and use the validation error to pick the best point to stop training, you heathen!\n",
    "\n",
    "Or you could change the network specification in hparams to add another layer (or 40) to network, because it's not deep until you've got at least 41 layers.\n",
    "\n",
    "Last, but not least, don't forget to give a good sign off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Peace()\n",
    "p.out()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
